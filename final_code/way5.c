#pragma config(Sensor, S1,     leftBumper,     sensorEV3_Touch, modeEV3Touch)
#pragma config(Sensor, S2,        backBumper,     sensorEV3_Touch, modeEV3Touch)
#pragma config(Sensor, S3,     gyro,           sensorEV3_Gyro)
#pragma config(Sensor, S4,     rightBumper,    sensorEV3_Touch, modeEV3Touch)
#pragma config(MotorPidSetting,  motorA,  255, 255, 65535, 255, 255,   65535, 65535, 65535)
#pragma config(MotorPidSetting,  motorB,  255, 255, 65535, 255, 255,   65535, 65535, 65535)
#pragma config(MotorPidSetting,  motorC,  255, 255, 65535, 255, 255,   65535, 65535, 65535)
#pragma config(MotorPidSetting,  motorD,  255, 255, 65535, 255, 255,   65535, 65535, 65535)
//*!!Code automatically generated by 'ROBOTC' configuration wizard               !!*//

/* This collection of functions allows basic movement capabilities in the least efficient manner possible.  */
/* If something goes wrong while calling one of these functions, be sure to read the comments above each      */
/* individual function as well as which variables it peruses.                                                                        */
/* ---------------------------------------------------------------------------------------------------------*/

//startMotor function starts the motor. It takes a motor and integer speed as parameters, and speed is limited to 100.

void startMotor(tMotor target, int speed)
{
   if(speed > 100)
   {
      speed = 100;
   }
   if(speed < -100)
   {
      speed = -100;
   }
   motor[target] = speed;
}

//turnDegrees takes a direction, degree value, and two integer values for slower and faster motors.
//*****FUNCTION REQUIRES THAT THERE BE MOTORS CALLED LEFTMOTOR AND RIGHTMOTOR, A GYRO CALLED GYRO, AND RIGHT = 1 and LEFT = 0

void turnDegrees(int direction, int degrees, int fasterMotor, int slowerMotor, tMotor rightMotor, tMotor leftMotor, tSensors gyro) //Turns the robot to a certain angle with whatever
{
   int RIGHT = 1;
   int LEFT = 0;                                                //motor speeds you would like.
   int initial = SensorValue[gyro];   //Take an initial gyro value so that degrees of change can be calculated.

   if(direction == RIGHT)            //Set the motor speeds based on which direction you are turning using the given speeds.
   {
      motor[leftMotor] = fasterMotor;
      motor[rightMotor] = slowerMotor;
   }
   else if (direction == LEFT)
   {
      motor[leftMotor] = slowerMotor;
      motor[rightMotor] = fasterMotor;
   }

   while(abs(initial - SensorValue[gyro]) < degrees)   //Wait until the absolute distance between the initial value and the
   {                                                                           //current gyro value becomes greater than the requested degrees.

   }

   motor[leftMotor] = motor[rightMotor] = 0;               //Stop the robot.

}

//turnTime is similar to turnDegrees, but it turns for a certain duration in milliseconds.
//********************************** NOTE THAT THIS FUNCTION WILL USE AND RESET TIMER 4 **************************************
//*****FUNCTION REQUIRES THAT THERE BE MOTORS CALLED LEFTMOTOR AND RIGHTMOTOR, RIGHT = 1, LEFT = 0


void turnTime(int direction, int timeMilliseconds, int fasterMotor, int slowerMotor, tMotor rightMotor, tMotor leftMotor) //Turns the robot for a certain duration with whatever
{
   int RIGHT = 1;
   int LEFT = 0;                                       //motor speeds you would like.
   clearTimer(T4);   //Take an initial timer value so that time change can be calculated.

   if(direction == RIGHT)            //Set the motor speeds based on which direction you are turning using the given speeds.
   {
      motor[leftMotor] = fasterMotor;
      motor[rightMotor] = slowerMotor;
   }
   else if (direction == LEFT)
   {
      motor[leftMotor] = slowerMotor;
      motor[rightMotor] = fasterMotor;
   }

   while(time1[T4]< timeMilliseconds)   //Wait until the timer's time is up.
   {

   }
}

//moveWithEncoders allows you to move precisely with motor encoders. It can (hopefully) move much more accurately than with time.

void moveWithEncoders(int millimeters, int speed, tMotor rightMotor, tMotor leftMotor)
{
   nMotorEncoder[leftMotor] = 0;
   int reqEncoderVal = millimeters / (56 * PI) * 360;
   motor[leftMotor] = motor[rightMotor] = speed;

   while(abs(nMotorEncoder[leftMotor]) < reqEncoderVal)
   {
      if(nMotorEncoder[leftMotor] < -32700 || nMotorEncoder[leftMotor] >= 32700)
       {
         reqEncoderVal -= abs(nMotorEncoder[leftMotor]);
         nMotorEncoder[leftMotor] = 0;
       }
    }

   motor[leftMotor] = motor[rightMotor] = 0;

}

//moveWithTime allows you to move somewhat inconsistently but is nice when you just want the robot to move in an approximate
//direction for an approximate distance.

void moveWithTime(int timeMSec, int speed, tMotor rightMotor, tMotor leftMotor)
{
   motor[rightMotor] = motor[leftMotor] = speed;
   wait1Msec(timeMSec);
   motor[leftMotor] = motor[rightMotor] = 0;

}

/*
PSEUDOCODE
Initialize an empty matrix with rows for states and columns for actions.
Initialize variables for the rate of adventure and learning (alpha).
Repeat forever:
   {
      Get the current robot state based on sensors.
      Default next action to an ambiguous case.
      Cycle through the array values for the current state to find the action which will give the highest utility.
      Generate a random number between 1 and 10 to see whether the robot should randomly explore.
      If no action has been found to be better than the others, or the random number is below the exploration threshold,
      generate a random number between 0 and 3 inclusive to represent the next action.
      Execute the action decided upon.
      Find the robot state after the action.
      Calculate the reward for being in the current state.
      Update the matrix value for the initial state and action pair based on the reward, the previous value, and potential
      utility values for the current state using the Q algorithm.
   }
*/


int getState()
{
   if(SensorValue[leftBumper] && SensorValue[rightBumper] && SensorValue[backBumper])
   {
      return 5;
   }
   else if(SensorValue[leftBumper] && SensorValue[rightBumper])
   {
      return 4;
   }
   else if(SensorValue[backBumper])
   {
      return 3;
   }
   else if(SensorValue[rightBumper])
   {
      return 2;
   }
   else if(SensorValue[leftBumper])
   {
      return 1;
   }
   else
   {
      return 0;
   }

}

void execute(int action, int state)
{
   //All of the functions used in this function are defined in the "movement.h" file.
   int sign = 1;

   if(state == 3)
   {
      sign = -1;
   }

   switch(action)
   {
      case 0:
         moveWithEncoders(100, 50, motorB, motorD);
         break;
      case 1:
         moveWithEncoders(100, -50, motorB, motorD);
         break;
      case 2:
         moveWithEncoders(75, -50 * sign, motorB, motorD);
         turnDegrees(1, 60, 50, -50, motorB, motorD, gyro);
         moveWithEncoders(175, 50 * sign, motorB, motorD);
         break;
      case 3:
         moveWithEncoders(75, -50 * sign, motorB, motorD);
         turnDegrees(0, 60, 50, -50, motorB, motorD, gyro);
         moveWithEncoders(175, 50 * sign, motorB, motorD);
         break;
      default:
         break;
   }
}

int getReward(int state)
{
   int reward;

   switch(state)
   {
      case 0:
         reward = 50;
         break;
      case 1:
         reward = -20;
         break;
      case 2:
         reward =  -20;
         break;
      case 3:
         reward = -20;
         break;
      case 4:
         reward = -40;
         break;
      case 5:
         reward = -50;
         break;
      default:
         return 0;
         break;
   }

   return reward;

}

int state;
int action;
int nextState;
int r;
int randNum;
int max;
int c;

task main()
{
   int QVALUES[6][4] = {{0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}, {0, 0, 0, 0}};

   // 0,0       0, 1      0, 2      0,3     //FIRST VALUE INDICES - STATES                  //SECOND VALUE INDICES - ACTIONS
   // 1,0       1, 1      1, 2      1,3     //0: No bumpers pressed (desired)               //0: Move forwards
   // 2,0       2, 1      2, 2      2,3     //1: Left bumper pressed                     //1: Move backwards
   // 3,0       3, 1      3, 2      3,3     //2: Right bumper pressed                     //2: Turn right
    // 4,0       4, 1      4, 2      4,3     //3: Back bumper pressed                      //3: Turn left
   // 5,0       5, 1      5, 2      5,3     //4: L+R bumper pressed
                                                 //5: All bumpers pressed

   float alpha = 0.1;      //Alpha is the rate of learning, the rate at which new data replaces previous knowledge.
   float discount = 0.5;      //Discount is the relative value of short term success versus long term success.
   int exploration = 2;    //Exploration is the rate at which the robot will move randomly despite there being a potentially better option.

   while(true)
   {
      state = getState();
          max = -32000;
      action = 4;

      for(c = 0; c < 4; c++)
      {
         if(QVALUES[state][c] > max)
         {
            max = QVALUES[state][c];
            action = c;
         }
      }

      writeDebugStreamLine("Best possible action found: %d", action);

      randNum = random(9);

      if(action == 4 || randNum + 1 <= exploration)
      {
         action = random(3);
      }

      writeDebugStreamLine("Actual action to execute: %d", action);
      execute(action, state);
      wait1Msec(450);
      nextState = getState();
      r = getReward(nextState);
      wait1Msec(50);

      max = -32000;

      for(c = 0; c < 4; c++)
      {
         if(QVALUES[nextState][c] > max)
         {
            max = QVALUES[nextState][c];
         }
      }

      //Implemented Q learning algorithm, should cause higher values to plateau instead of becoming infinitely higher.
      //Curr peak = ~80
      QVALUES[state][action] = (int) (QVALUES[state][action]) + alpha * (r + (discount * max) - QVALUES[state][action]);

      //Explanation: alpha is the rate of learning, the rate at which newly learned information replaces old information.
      //Discount is the comparative worth of short term rewards versus longer term rewards.

      writeDebugStreamLine("Initial state %d, Prev Action %d, Reward %d, Set Value to %d", state, action, r, QVALUES[state][action]);
      wait1Msec(500);

   } //Infinite loop ends here. Anything after this will not run.

}